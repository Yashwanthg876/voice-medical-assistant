{% extends "base.html" %}
{% block content %}

<style>
.assistant-container {
    max-width: 900px;
    margin: auto;
}

.assistant-header {
    margin-bottom: 20px;
}

.assistant-header h1 {
    margin-bottom: 5px;
}

.assistant-header p {
    color: #555;
}

.voice-card {
    background: white;
    padding: 30px;
    border-radius: 14px;
    box-shadow: 0 4px 12px rgba(0,0,0,0.08);
    text-align: center;
}

.mic-button {
    width: 90px;
    height: 90px;
    border-radius: 50%;
    border: none;
    background-color: #dc2626;
    color: white;
    font-size: 36px;
    cursor: pointer;
    margin: 20px 0;
    transition: transform 0.2s, box-shadow 0.2s;
}

.mic-button:hover {
    transform: scale(1.05);
    box-shadow: 0 6px 15px rgba(0,0,0,0.15);
}

.status {
    font-weight: bold;
    margin-top: 10px;
}

.output-card {
    margin-top: 25px;
    background: #f9fafb;
    padding: 20px;
    border-radius: 10px;
    text-align: left;
}

.output-label {
    font-weight: bold;
    margin-bottom: 5px;
    color: #374151;
}
</style>

<div class="assistant-container">

    <div class="assistant-header">
        <h1>ğŸ™ï¸ Voice Medical Assistant</h1>
        <p>
            Speak naturally to describe your symptoms or request medical help.
            The assistant will analyze your voice input and respond accordingly.
        </p>
    </div>

    <div class="voice-card">
        <p class="status" id="status">Press the microphone and start speaking</p>

        <button class="mic-button" onclick="startRecording()">ğŸ¤</button>

        <div class="output-card">
            <div class="output-label">ğŸ“ Transcribed Text</div>
            <p id="transcript">â€”</p>

            <div class="output-label" style="margin-top:15px;">ğŸ§  Detected Intent</div>
            <p id="intent">â€”</p>
        </div>
    </div>

</div>

<script>
let mediaRecorder;
let audioChunks = [];

function startRecording() {
    document.getElementById("status").innerText = "Listening... please speak";

    navigator.mediaDevices.getUserMedia({ audio: true })
        .then(stream => {
            mediaRecorder = new MediaRecorder(stream);
            mediaRecorder.start();

            audioChunks = [];

            mediaRecorder.ondataavailable = e => {
                audioChunks.push(e.data);
            };

            mediaRecorder.onstop = () => {
                document.getElementById("status").innerText = "Processing voice input...";

                const audioBlob = new Blob(audioChunks, { type: "audio/webm" });
                const formData = new FormData();
                formData.append("audio", audioBlob);

                fetch("/upload_audio", {
                    method: "POST",
                    body: formData
                })
                .then(res => res.json())
                .then(data => {
                    document.getElementById("transcript").innerText = data.text || "No text detected";
                    document.getElementById("intent").innerText = data.intent || "Unknown";
                    document.getElementById("status").innerText = "Press the microphone to speak again";
                })
                .catch(() => {
                    document.getElementById("status").innerText = "Error processing audio";
                });
            };

            // Auto stop after 6 seconds
            setTimeout(() => {
                mediaRecorder.stop();
            }, 6000);
        })
        .catch(() => {
            document.getElementById("status").innerText = "Microphone access denied";
        });
}
</script>

{% endblock %}